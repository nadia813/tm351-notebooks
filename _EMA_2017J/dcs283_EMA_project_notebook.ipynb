{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMA Project Notebook\n",
    "__Name:__ Daniel Smith\n",
    "\n",
    "__PI:__ A7603242"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Please note:_\n",
    "\n",
    "This notebook records all the steps I took in the investigation.  It requires that the provided KS2 & KS4 data has been unzipped and is located in the `data/2015-2016/` folder to run.  When run it will clean the required csv files and store them in a MongoDB.\n",
    "\n",
    "To carry out all steps may take a little time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import bson\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import the needed machine learning libraries\n",
    "from sklearn import cluster\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "Use these links to jump to a section.\n",
    "\n",
    "[Initial look at the ks4 dataset](#initial_look)\n",
    "\n",
    "[Choosing MongoDB](#mongo)\n",
    "\n",
    "---\n",
    "[Data preparation](#preparation)\n",
    "   - [Importing the KS2 data](#importing_ks2)\n",
    "   - [Importing the KS4 data](#importing_ks4)\n",
    "      - [Importing the abbreviations file](#abbr)\n",
    "      - [Importing the ks4 meta file](#meta)\n",
    "      - [Importing the data](#data)\n",
    "---\n",
    "[Q1, KS4 Investigation](#q1)\n",
    "   - [Choosing performance measures](#measures)\n",
    "   - [Additional cleaning](#add_clean)\n",
    "   - [Does the type of school impact the results students acheive at keystage 4?](#Q1_a)\n",
    "      - [summary stats](#ks4_summary_stats)\n",
    "      - [Grouped school type plots](#school_type_plots)\n",
    "      - [Whole dataset kMeans cluster analysis](#machine_learning)\n",
    "      - [Grouped data kMeans cluster analysis](#grouped_cluster)\n",
    "      - [Silhouette plots](#silhouette)\n",
    "      - [School Scatter](#school_scatter)\n",
    "      - [Findings](#q1_findings)\n",
    "---\n",
    "[Q2, KS2 - KS4 Investigation](#q2)\n",
    "   - [Do schools that perform well at KS2 deliver as good or better results at KS4.](#q2)\n",
    "   - [Joining the datasets](#joining)\n",
    "   - [Summary stats](#stats)\n",
    "   - [Plotting](#plotting)\n",
    "   - [Pearson R^2](#pearson)\n",
    "   - [Findings](#q2_findings)\n",
    "\n",
    "\n",
    "[Cleanup - remove the database](#cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a folder for storing my working files as I go along.\n",
    "# make a folder for plot image png's generated\n",
    "!mkdir -p plot_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up basic plot styles\n",
    "sns.set_style('ticks')\n",
    "sns.set_palette(palette='Paired', n_colors=12)\n",
    "\n",
    "# set up plots for nice exporting\n",
    "#https://matplotlib.org/users/customizing.html\n",
    "plt.rcParams.update({'axes.titlesize': 35,\n",
    "                     'axes.labelsize': 30,\n",
    "                     'lines.linewidth': 5,\n",
    "                     'lines.markersize': 12,\n",
    "                     'legend.loc': 'best',\n",
    "                     'legend.fontsize': 20,\n",
    "                     'xtick.labelsize': 20,\n",
    "                     'ytick.labelsize': 20,\n",
    "                     'figure.figsize': [20, 16]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"initial_look\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial look at the KS4 results dataset\n",
    "Let's have a quick look at the data we will be looking at for the EMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 'data/2015-2016/england_ks4final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l 'data/2015-2016/england_ks4final.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 5489 rows of data, there appears to be a large number of columns and a lot of codes that I'll need to look up.  There are a also a number of `NA` and `NP` values that could be missing data.  As well as this results data I will need to find and import the relevent metadata file.\n",
    "\n",
    "Before importing the dataset I will need to decide which storage method to use.\n",
    "\n",
    "<a name=\"mongo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With so many columns to investigate I am leaning towards using a DBMS to make the querying of the data more efficient than in a pandas dataframe.  Therefore, I will import the data into MongoDB.  I chose a document database system as they are far more flexible than a relational database.  In this investigation it may become necessary to add fields to certain documents for example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a connection to mongodb server\n",
    "client = pymongo.MongoClient('mongodb://localhost:27351')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment to remove the database if needed\n",
    "# client.drop_database('schools_db')\n",
    "# client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup a schools_db database on mongo\n",
    "db = client.schools_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"preparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can investigate the data we will need to have a quick look at it, determine what cleaning, if any, is needed.  Carry out the cleaning and store it for access in tn appropriate form.  \n",
    "\n",
    "However before doing anything I will import the KS2 data in the same way as was done in `dcs283_TMA02_Question2b-pd`  I will then store the resultant dataframe into mongo for analysis later on.\n",
    "\n",
    "<a name=\"importing_ks2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the KS2 data\n",
    "\n",
    "\n",
    "All of this section is the same as in the `TMA02_Question2b-pd` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__ ----------- Beginning of TMA02 code -----------  __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the LEA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leas_df = pd.read_csv('data/2015-2016/la_and_region_codes_meta.csv')\n",
    "leas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the KS2 data\n",
    "Most of the field names are given in the `ks2_meta` file, so we'll use that to keep track of the types of various columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2cols = pd.read_csv('data/2015-2016/ks2_meta.csv')\n",
    "ks2cols['Field Name'] = ks2cols['Field Name'].apply(lambda r: r.strip(),)\n",
    "ks2cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns contain integers, but _**pandas**_ will treat any numeric column with `na` values as `float64`, due to NumPy's number type hierarchy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_cols = [c for c in ks2cols['Field Name'] \n",
    "            if c.startswith('T')\n",
    "            if c not in ['TOWN', 'TELNUM', 'TKS1AVERAGE']]\n",
    "int_cols += ['RECTYPE', 'ALPHAIND', 'LEA', 'ESTAB', 'URN', 'URN_AC', 'ICLOSE']\n",
    "int_cols += ['READ_AVERAGE', 'GPS_AVERAGE', 'MAT_AVERAGE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns contain percentages. We'll convert these to floating point numbers on import.\n",
    "\n",
    "Note that we also need to handle the case of `SUPP` and `NEW` in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p2f(x):\n",
    "    if x.strip('%').isnumeric():\n",
    "        return float(x.strip('%'))/100\n",
    "    elif x in ['SUPP', 'NEW', 'LOWCOV', 'NA', '']:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the columns to try to convert from percentages. Note that we can be generous here, as columns like PCODE (postcode) will return the original value if the conversion fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percent_cols = [f for f in ks2cols['Field Name'] if f.startswith('P')]\n",
    "percent_cols += ['WRITCOV', 'MATCOV', 'READCOV'] \n",
    "percent_cols += ['PTMAT_HIGH', 'PTREAD_HIGH', 'PSENELSAPK', 'PSENELK', 'PTGPS_HIGH']\n",
    "percent_converters = {c: p2f for c in percent_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks2_df = pd.read_csv('data/2015-2016/england_ks2final.csv', \n",
    "                   na_values=['SUPP', 'NEW', 'LOWCOV', 'NA', '', ' '],\n",
    "                   converters=percent_converters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the summary rows, keeping just the rows for mainstream and special schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks2_df = ks2_df[(ks2_df['RECTYPE'] == 1) | (ks2_df['RECTYPE'] == 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert everything to numbers, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks2_df = ks2_df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the LEA data into the school data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_df = pd.merge(ks2_df, leas_df, on=['LEA'])\n",
    "ks2_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ ----------- END of TMA02 code -----------  __\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert and store the KS2 dataframe into Mongo for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a collection on the database for the ks2 results data\n",
    "ks2 = db.ks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe into a list of dicts and store in Mongo\n",
    "\n",
    "# the 'results' argument is needed to get a list of dicts\n",
    "ks2.insert_many(ks2_df.to_dict('records'))\n",
    "\n",
    "# snippet reference is from:\n",
    "# https://stackoverflow.com/questions/33979983/insert-rows-from-pandas-dataframe-into-mongodb-collection-as-individual-document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check we got them all\n",
    "ks2.find().count(), len(ks2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great all present and correct.  Let's look at one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2.find_one()['GPS_AVERAGE_L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks2.find({'GPS_AVERAGE_L': np.nan}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like everything is set up.  We will need to bear the NaN values and missing values that the `p2f` function made into `0.0` in mind throughout the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have finished with it we can get rid of the ks2 dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del ks2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"importing_ks4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the KS4 results dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can investigate the data we will need to have a look at it, determine what cleaning if any needs to be done, and store it for access in an appropriate form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the KS4 results dataset\n",
    "Let's have a quick look at the data we will be looking at for the EMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 'data/2015-2016/england_ks4final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l 'data/2015-2016/england_ks4final.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 5489 rows of data, there appears to be a large number of columns and a lot of codes that I'll need to look up.  There are a also a number of `NA` and `NP` values that could be missing data.  As well as this results data I will need to find and import the relevent metadata file.\n",
    "\n",
    "Looking through the data/2015-2016 folder there are a number of files that have information on these codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/2015-2016/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an abbreviations file, stored as an xlsx file.  I'll have a quick glance at it in excel.  Having looked the abbreviation up in the abbreviations file we can see that they have the following meanings:\n",
    "\n",
    "- _NA_: Not applicable\n",
    "- _NP_: Not Published\n",
    "- _NE_: No entries\n",
    "- _SUPP_: Suppressed (5 or fewer in cohort)\n",
    "- _LOWCOV_: Low coverage (less than 50% of the cohort\n",
    "- _NEW_: New institution\n",
    "\n",
    "The abbreviations file also has listings of all the school types (NFTYPE) that I will need.  I'll grab that for use later on.\n",
    "\n",
    "<a name='abbr'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the abbreviations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the abbreviations file\n",
    "abbr_df = pd.read_excel('data/2015-2016/abbreviations.xlsx')\n",
    "abbr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the school types are rows 2-25, I'll store them as a dict for reference later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relabel the columns\n",
    "abbr_df.columns = ['label', 'expanded', 'not_needed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary to easily look up the school types\n",
    "nftypes = {}\n",
    "for index, row in abbr_df[3:26].iterrows():\n",
    "    nftypes[row['label'].strip()] = row['expanded'].strip()\n",
    "    \n",
    "nftypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, while we have the abbreviations available I'll store the missing value types for reference later on if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary to refer to later of the missing types\n",
    "missing_types = {}\n",
    "for i, r in abbr_df[45:51].iterrows():\n",
    "    missing_types[r['label']] = r['expanded']\n",
    "\n",
    "missing_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now delete the abbr_df as it won't be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del abbr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='meta'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the KS4 Metadata file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to analyse the data we need to be able to reference the columns and the codes they represent.  I'll import the KS4_meta.csv file into the database and use it to help me understand the data in the KS4 results dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 data/2015-2016/ks4_meta.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l data/2015-2016/ks4_meta.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 lines.. I'll try loading directly into Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/bin/mongoimport --port 27351 --drop --db schools_db --collection ks4_meta \\\n",
    "    --type csv --headerline --ignoreBlanks \\\n",
    "    --file data/2015-2016/ks4_meta.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there is an issue with the import.  I'll try importing it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_meta_df = pd.read_csv('data/2015-2016/ks4_meta.csv')\n",
    "ks4_meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That imported ok.  But there are a few extra columns for my needs (I only need it to look up the description for a given term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduce the dataframe to the columns of interest\n",
    "ks4_meta_df = ks4_meta_df[['Metafile heading', 'Metafile description']]\n",
    "# relabel them to match my target format\n",
    "ks4_meta_df.columns = ['label', 'expanded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it looks ok\n",
    "ks4_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a reference to the db.collection \n",
    "ks4_meta = db.ks4_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_meta.insert_many(ks4_meta_df.to_dict('records'))\n",
    "# snippet reference is from:\n",
    "# https://stackoverflow.com/questions/33979983/insert-rows-from-pandas-dataframe-into-mongodb-collection-as-individual-document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_meta.find_one({'label': 'NFTYPE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to add the codes from the abbreviations dictionary to this document since it is one of the backbones to my investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_meta.update_one({'label': 'NFTYPE'}, \n",
    "                    {'$set': {'codes': nftypes}})\n",
    "\n",
    "ks4_meta.find_one({'label': 'NFTYPE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll do the same for the `RECTYPE` label by splitting the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the correct document\n",
    "r = ks4_meta.find_one({'label': 'RECTYPE'})\n",
    "\n",
    "# checks that we haven't already updated the document\n",
    "# then if not splits the description string, adding a code key\n",
    "# to reference each school type\n",
    "if 'codes' not in r.keys():\n",
    "    expanded = r['expanded']\n",
    "    e = expanded[:11]\n",
    "    codelist = expanded[13:-1].split('; ')\n",
    "    keys = [c[:1] for c in codelist]\n",
    "    values = [c[2:] for c in codelist]\n",
    "    codes = (dict(list(zip(keys, values))))\n",
    "    ks4_meta.update_one({'_id': r['_id']},\n",
    "                        {'$set': {'expanded': e,\n",
    "                                  'codes': codes}})\n",
    "\n",
    "# check that it was processed correctly\n",
    "ks4_meta.find_one({'label': 'RECTYPE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  That is most of the cleaning I need to do for the ks4_meta file.  If I were to be doing a different investigation I would consider merging in the LEA data here, but for the investigations I plan to do I don't think we need it and we already have it stored from earlier on (importing ks2) as the `LEA` dataframe which we can reference if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  Now in the tm351 module materials we had some handy collections provided by the module team that enabled us to quickly look up the labels and codes of a given accident.  I'll borrow that idea here for my purposes.  Because, I will need to do the same for the KS2 dataset, I'll wrap them in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code adapted from the p14 accidents dataset notebooks\n",
    "\n",
    "def expanded_label(meta):\n",
    "    # Load the expanded names of keys and human-readable codes into memory\n",
    "    expanded_name = collections.defaultdict(str)\n",
    "    for e in meta.find({'expanded': {\"$exists\": True}}):\n",
    "        expanded_name[e['label']] = e['expanded']\n",
    "\n",
    "    label_of = collections.defaultdict(str)\n",
    "    for l in meta.find({'codes': {\"$exists\": True}}):\n",
    "        for c in l['codes']:\n",
    "            try:\n",
    "                label_of[l['label'], int(c)] = l['codes'][c]\n",
    "            except ValueError: \n",
    "                label_of[l['label'], c] = l['codes'][c]\n",
    "    # return both as a tuple\n",
    "    return (expanded_name, label_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the expanded_name and label_of for ks4_meta\n",
    "ks4_expanded_name, ks4_label_of = expanded_label(ks4_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it works\n",
    "[(c, ks4_label_of['RECTYPE', c]) for k, c in ks4_label_of if k == 'RECTYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_expanded_name['NFTYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_label_of['NFTYPE', 'AC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great that all is working, I can now delete the ks4_meta_df, as the information is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del ks4_meta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll quickly repeat the same steps for KS2_meta data to include the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relabel the columns of ks2cols\n",
    "ks2cols.columns = ['not_needed', 'label', 'expanded']\n",
    "\n",
    "# create a collection in the database\n",
    "ks2_meta = db.ks2_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store them into the database\n",
    "ks2_meta.insert_many(ks2cols[['label', 'expanded']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_meta.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the splitting of the `RECTYPE`\n",
    "# select the correct document\n",
    "r = ks2_meta.find_one({'label': 'RECTYPE'})\n",
    "\n",
    "# checks that we haven't already updated the document\n",
    "# then if not splits the description string, adding a code key\n",
    "# to reference each school type\n",
    "if 'codes' not in r.keys():\n",
    "    expanded = r['expanded']\n",
    "    e = expanded[:11]\n",
    "    codelist = expanded[13:-1].split('; ')\n",
    "    keys = [c[:1] for c in codelist]\n",
    "    values = [c[2:] for c in codelist]\n",
    "    codes = (dict(list(zip(keys, values))))\n",
    "    ks2_meta.update_one({'_id': r['_id']},\n",
    "                        {'$set': {'expanded': e,\n",
    "                                  'codes': codes}})\n",
    "\n",
    "# check that it was processed correctly\n",
    "ks2_meta.find_one({'label': 'RECTYPE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And add the nftype to the meta collection\n",
    "ks2_meta.update_one({'label': 'NFTYPE'}, \n",
    "                    {'$set': {'codes': nftypes}})\n",
    "\n",
    "ks2_meta.find_one({'label': 'NFTYPE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finally, set up the expanded_name and label_of for ks4_meta\n",
    "ks2_expanded_name, ks2_label_of = expanded_label(ks2_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check they work ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it works\n",
    "[(c, ks2_label_of['RECTYPE', c]) for k, c in ks2_label_of if k == 'RECTYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_label_of['NFTYPE', 'IND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_expanded_name['TELIG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great that is all the meta data handled, and we can now go about importing the KS4 data into the database and cleaning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete the ks2cols dataframe as we don't need it anymore\n",
    "del ks2cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the KS4 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I import the data I will have another quick look at the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! head -5 'data/2015-2016/england_ks4final.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restate what was noted earlier there appears to be a great number of columns, and a large number of missing values.  How many rows are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l 'data/2015-2016/england_ks4final.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's carry out similar steps to those we carried out in importing the ks2 data.  Again this is going to be adapted from the TMA02-Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_df = pd.read_csv('data/2015-2016/england_ks4final.csv')\n",
    "ks4_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A straight import gives an error (`DtypeWarning`).  Let's look at the file using the tools learned in p2 of the tm351 materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's quickly look at the file using command line\n",
    "!file 'data/2015-2016/england_ks4final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and check it using chardet\n",
    "import chardet\n",
    "\n",
    "# open the file and read the contents in as a byte object\n",
    "testfile = open('data/2015-2016/england_ks4final.csv', 'rb').read()\n",
    "\n",
    "# detect the file encoding\n",
    "chardet.detect(testfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ks4_df = pd.read_csv('data/2015-2016/england_ks4final.csv', encoding='UTF-8-SIG')\n",
    "ks4_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the columns are mixed with an 'object' datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_dt_df = pd.DataFrame()\n",
    "for col in ks4_df.columns:\n",
    "    ks4_dt_df[col] = pd.to_numeric(ks4_df[col], errors='ignore')\n",
    "\n",
    "ks4_dt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_dt_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not getting very far here.  I'll try and follow the steps from Q2. If after that I have still made no progress I think that the most efficient way to get to the bottom of it will be to take a look at the file in OpenRefine to clean the mixed datatypes and determine what to do with the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__--- steps adapted from tma02 cleaning ---__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll find out which columns have percentages in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look through the meta file and get the columns that are percentages.\n",
    "percent_cols_list = [(l, ks4_expanded_name[l]) \n",
    "                     for l in ks4_expanded_name \n",
    "                     if 'percent' in ks4_expanded_name[l].lower()]\n",
    "percent_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the column headings to a list\n",
    "percent_cols = [p[0] for p in percent_cols_list]\n",
    "percent_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int columns\n",
    "int_col_list = [(l, ks4_expanded_name[l])\n",
    "                for l in ks4_expanded_name \n",
    "                if 'number' in ks4_expanded_name[l].lower()]\n",
    "int_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, save out just the column labels\n",
    "# Save just the column headings\n",
    "int_cols = [i[0] for i in int_col_list]\n",
    "int_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind myself of the missing type codes\n",
    "missing_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percent_converters = {c: p2f for c in percent_cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the file to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_df = pd.read_csv('data/2015-2016/england_ks4final.csv',\n",
    "                     na_values=['SUPP', 'NEW', 'LOWCOV', 'NA', ''],\n",
    "                     converters=percent_converters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still showing the error for the data types.  I will continue walking through the cleaning steps from tma02-q2.  For our questions will focus on only mainstream schools we can drop those that are not of `RECTYPE` == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks4_df = ks4_df[ks4_df['RECTYPE'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert everything to numbers, if possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks4_df = ks4_df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the LEA data into the school data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_df = pd.merge(ks4_df, leas_df, on=['LEA'])\n",
    "ks4_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is looking better I'll now import these into mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a collection in the database\n",
    "ks4 = db.ks4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the cleaned dataframe to the database\n",
    "ks4.insert_many(ks4_df.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the correct number of documents were included\n",
    "len(ks4_df), ks4.find().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an independent school since they don't need to publish their data there are a lot of missing values.  This is something we will need to be mindful of when carrying out the analysis.  Although the percentages have been handled, there are still a number of other measures that are still showing 'NP'.  Since the majority of the measures I will be looking at will be percentages, instead of working through every single measure I will determine those I want to use in my investigation and then clean those as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_expanded_name['P8MEA_AV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many independent schools are in the dataset?\n",
    "ks4.find({'NFTYPE': 'IND'}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at another school type and find out how many there are\n",
    "nftypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many Community schools are there?\n",
    "ks4.find({'NFTYPE': 'CY'}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete the dataframes I don't need\n",
    "del ks4_df, ks4_dt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good things look they are clean enough to start working on the investigation.\n",
    "<a name='q1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keystage 4 Investigation.  \n",
    "\n",
    "## Q -  Does the type of school impact the results students acheive at keystage 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are a large number of documents in the dataset (after taking out the non-mainstream schools)\n",
    "\n",
    "<a name=\"measures\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing performance measures\n",
    "\n",
    "The first thing I need to decide before I can analyse the data is to decide what I mean by 'good performance' and once that is ascertained which of the many data points I will use as measures to base my comparison of school types on.\n",
    "\n",
    "For a long time the standard measure of successful schools was the percentage of pupils achieving grades A*-C in Maths and English.  This has changed recently with the government introducing new metrics the 'Progress 8' and 'Achievement 8' and the introduction of the English Baccalaurette which includes English, Maths, Sciences (incl. computer science, history/geograghy a modern/ancient foreign language).  So, I will try to look at these as the success measure of a school, and if possible combine them.\n",
    "\n",
    "So the first step I need to take is to identify the keys for the data I want to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the keys and values of the meta data\n",
    "# to help choose the columns I will use\n",
    "for d in ks4_meta.find():\n",
    "    print(d['label'], ':', d['expanded'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through these it is clear that I will need to be selective in choosing measures.  There are thousands of ways to subdivide this dataset and investigate it.  I will be focusing on the Average numbers for the whole school, for every student.  There will of course be cases where this skews the results.\n",
    "\n",
    "For instance, at schools with many disadvantaged students the average scores could be affected and without looking including measures the results can not be fully comprehensive.  That said it is beyond the scope of this project to examine every single possible facet of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many scores are there for the attainment 8 measure?\n",
    "test_df = pd.DataFrame(list(ks4.find({}, {'ATT8SCR':1, '_id': 0})))\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and how many for attainment 8 in 2015?\n",
    "test_df = pd.DataFrame(list(ks4.find({}, {'ATT8SCR_15':1, '_id': 0})))\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will look at the following basic performance measures to compare KS4 schools types.\n",
    "\n",
    "- `PTEBACC_PTQ_EE` : Percentage of key stage 4 pupils achieving the English Baccalaureate \n",
    "- `PTAC5EM_PTQ_EE` : Percentage of pupils achieving 5+ A*-C or equivalents including A*-C in both English and mathematics GCSEs \n",
    "- `ATT8SCR` : Average Attainment 8 score per pupil\n",
    "- `P8MEA` : Progress 8 measure \n",
    "- `URN`: To keep track of which school we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of just the measures I will be investigating.\n",
    "ks4_results_df = pd.DataFrame(list(ks4.find({}, \n",
    "                                {'NFTYPE':1, \n",
    "                                'PTEBACC_PTQ_EE':1,\n",
    "                                'PTAC5EM_PTQ_EE':1,\n",
    "                                'ATT8SCR':1,\n",
    "                                'P8MEA':1,\n",
    "                                'URN': 1,\n",
    "                                 '_id': 0\n",
    "                               })))\n",
    "ks4_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there is still some cleaning to do.  In particular the `NP` values.  Also I will need to decide what to do with the independent schools.\n",
    "\n",
    "<a name='add_clean'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the missing types\n",
    "missing_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that clean values from string to number\n",
    "def clean(value):\n",
    "    if type(value) == str:\n",
    "        if value.strip() in missing_types.keys():\n",
    "            return np.nan\n",
    "        else:\n",
    "            return value\n",
    "    else:\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a list of the measures I'll use to clean on\n",
    "measures = [c for c in ks4_results_df.columns if c != 'URN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update the database with cleaned values\n",
    "for d in ks4.find():\n",
    "    for k in d.keys():\n",
    "        if k in measures:\n",
    "            # update the value on the database\n",
    "            ks4.update_one({'_id': d['_id']},\n",
    "                           {'$set': {k: clean(d[k])}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate the dataframe\n",
    "ks4_results_df = pd.DataFrame(list(ks4.find({}, \n",
    "                                {'NFTYPE':1,\n",
    "                                 'PTEBACC_PTQ_EE':1,\n",
    "                                 'PTAC5EM_PTQ_EE':1,\n",
    "                                 'ATT8SCR':1,\n",
    "                                 'P8MEA':1,\n",
    "                                 'URN':1,\n",
    "                                 '_id':0\n",
    "                                })))\n",
    "ks4_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is better.  Next I'll drop the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview what dropping the missing values will do\n",
    "ks4_results_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will still be a few rows still with missing data particularly the `F NFTYPE`. What is that school type anyway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_label_of['NFTYPE','F']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at one file to see if we can see what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4.find_one({'NFTYPE': 'F'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah a lot of blank space there `' '` I'll clean that up by removing them from the database completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop through the documents and remove keys that have ' ' as the value\n",
    "# this step could take some time\n",
    "\n",
    "for d in ks4.find({}):\n",
    "    for k in d.keys():\n",
    "        if d[k] == ' ':\n",
    "            ks4.update_one({'_id': d['_id']},\n",
    "                           {'$unset': {k: ''}})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataframe again\n",
    "ks4_results_df = pd.DataFrame(list(ks4.find({}, \n",
    "                                {'NFTYPE':1, \n",
    "                                'PTEBACC_PTQ_EE':1,\n",
    "                                'PTAC5EM_PTQ_EE':1,\n",
    "                                'ATT8SCR':1,\n",
    "                                'P8MEA':1,\n",
    "                                'URN':1,\n",
    "                                '_id':0\n",
    "                               })))\n",
    "ks4_results_df.head(10)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since independent schools do not publish their data when I drop the missing data I will also lose these.  That is ok for the scope of this investigation but it should be noted.\n",
    "\n",
    "Drop the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the na. missing data\n",
    "ks4_results_df.dropna(inplace=True)\n",
    "# reset the index\n",
    "ks4_results_df.reset_index(inplace=True, drop=True)\n",
    "#preview the dataframe\n",
    "ks4_results_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great that is looking better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_results_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still two problem columns (`ATT8SCR` and `P8MEA`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's peak at the values\n",
    "ks4_results_df['ATT8SCR'].unique()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "right so they are all strings.  Is it the same for P8MEA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's peak at the values\n",
    "ks4_results_df['P8MEA'].unique()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok so let's clean those up too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update the database documents\n",
    "for d in ks4.find():\n",
    "    for k in d.keys():\n",
    "        if k in ['P8MEA', 'ATT8SCR']:\n",
    "            ks4.update_one({'_id': d['_id']},\n",
    "                           {'$set': {k: float(d[k])}}\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the values have been updated\n",
    "ks4.find_one({'NFTYPE':'CY'},{'P8MEA':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now I can recreate the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the dataframe again\n",
    "ks4_results_df = pd.DataFrame(list(ks4.find({}, \n",
    "                                {'NFTYPE':1, \n",
    "                                'PTEBACC_PTQ_EE':1,\n",
    "                                'PTAC5EM_PTQ_EE':1,\n",
    "                                'ATT8SCR':1,\n",
    "                                'P8MEA':1,\n",
    "                                'URN':1,\n",
    "                                '_id':0\n",
    "                               })))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the na. missing data\n",
    "ks4_results_df.dropna(inplace=True)\n",
    "# reset the index\n",
    "ks4_results_df.reset_index(inplace=True, drop=True)\n",
    "#preview the dataframe\n",
    "ks4_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Q1_a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q: Does the type of school impact the results students acheive at keystage 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ks4_summary_stats\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaned data stats\n",
    "ks4_results_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_results_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many values are 0.0 (some were possibly added by the p2f function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCSE A*-C\n",
    "ks4_results_df[ks4_results_df['PTAC5EM_PTQ_EE']==0]['PTAC5EM_PTQ_EE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCSE A*-C\n",
    "ks4_results_df[ks4_results_df['PTEBACC_PTQ_EE']==0]['PTEBACC_PTQ_EE'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are relatively small numbers.  But should still keep these in mind when calculating values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='school_type_plots'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# School type grouped plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the mean results by school type\n",
    "grouped_res = ks4_results_df[['NFTYPE', 'ATT8SCR', 'P8MEA', 'PTAC5EM_PTQ_EE', 'PTEBACC_PTQ_EE']].groupby(by='NFTYPE').mean()\n",
    "grouped_df = pd.DataFrame(grouped_res)\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise them quickly\n",
    "grouped_df.plot(kind='bar', subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting there appears to be something of a pattern in these groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort the values to compare\n",
    "grouped_df.sort_values('PTAC5EM_PTQ_EE').plot(kind='bar', subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_expanded_name['P8MEA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tidy up these plots a little by adding human readable codes.  Changing percentages into 0-100 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# provide human readable codes\n",
    "grouped_df.index = [nftypes[code] for code in grouped_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the percentages range from 0-100\n",
    "grouped_df['PTAC5EM_PTQ_EE'] = grouped_df['PTAC5EM_PTQ_EE']*100\n",
    "grouped_df['PTEBACC_PTQ_EE'] = grouped_df['PTEBACC_PTQ_EE']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.sort_values('PTAC5EM_PTQ_EE').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does appear to be a relationship between school type and the results acheived. using the three most common measures.  The mean values for the school type appears to relate to the other measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see them in pairs to see how they compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of mean EBACC to GCSE performance by school type (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[['PTEBACC_PTQ_EE', 'PTAC5EM_PTQ_EE']].sort_values('PTEBACC_PTQ_EE').plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[['PTEBACC_PTQ_EE', 'PTAC5EM_PTQ_EE']].sort_values('PTEBACC_PTQ_EE').plot(kind=\"bar\", subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a link between EBacc and GCSE performance and the the school type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of mean Attainment8 to Progress8 performance by school type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[['ATT8SCR', 'P8MEA']].sort_values('ATT8SCR').plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this isn't that clear - I'll use subplots to show more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[['ATT8SCR', 'P8MEA']].sort_values('ATT8SCR').plot(kind=\"bar\", subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all of these cases there appears to be a pattern.  Let's get the top performers and low performers for each measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in grouped_df.columns:\n",
    "    p = grouped_df[c].idxmax(), grouped_df[c].idxmin()\n",
    "    print(c, ': ', ks4_expanded_name[c])\n",
    "    print('Top school type: ', round(grouped_df.loc[p[0]][c], 2), p[0])\n",
    "    print('Bottom school type', round(grouped_df.loc[p[1]][c], 2), p[1], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly by every measure considered _City Technology College_ are top and the _Further Education Sector Institutions_ are bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double checking - accounting for the potential extra 0.0 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data preparation phase we used the p2f function.  However, some of the values may have been set to 0 and could be skewing these analysis.  However, there are only a small number of values.  I will calculate the mean value of the column without them and replace the 0 with those and see whether it negatively impacts the results of the earlier findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll repeat the same steps without the 0.0 values that could be influenced by the import.  To compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the rows that could be effected\n",
    "res = ks4_results_df[(ks4_results_df['PTAC5EM_PTQ_EE']!=0) & (ks4_results_df['PTEBACC_PTQ_EE']!=0)]\n",
    "\n",
    "# group the data by school type\n",
    "grouped_res = res[['NFTYPE', 'ATT8SCR', 'P8MEA', 'PTAC5EM_PTQ_EE', 'PTEBACC_PTQ_EE']].groupby(by='NFTYPE').mean()\n",
    "grouped_gt0_df = pd.DataFrame(grouped_res)\n",
    "grouped_gt0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the percentages prettier (out of 100)\n",
    "grouped_gt0_df['PTAC5EM_PTQ_EE'] = grouped_gt0_df['PTAC5EM_PTQ_EE']*100\n",
    "grouped_gt0_df['PTEBACC_PTQ_EE'] = grouped_gt0_df['PTEBACC_PTQ_EE']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# provide human readable codes\n",
    "grouped_gt0_df.index = [nftypes[code] for code in grouped_gt0_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gt0_df.sort_values('P8MEA').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of EBACC to GCSE performance by school type (%) non-0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gt0_df[['PTEBACC_PTQ_EE', 'PTAC5EM_PTQ_EE']].sort_values('PTEBACC_PTQ_EE').plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gt0_df[['PTEBACC_PTQ_EE', 'PTAC5EM_PTQ_EE']].sort_values('PTEBACC_PTQ_EE').plot(kind=\"bar\", subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a link between EBacc and GCSE performance and the the school type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Attainment8 to Progress8 performance by school type ( non 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gt0_df[['ATT8SCR', 'P8MEA']].sort_values('ATT8SCR').plot(kind=\"bar\", subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all of these cases there appears to be a pattern.  Let's get the top performers and low performers for each measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in grouped_gt0_df.columns:\n",
    "    p = grouped_gt0_df[c].idxmax(), grouped_gt0_df[c].idxmin()\n",
    "    print(c, ': ', ks4_expanded_name[c])\n",
    "    print('Top school type: ', round(grouped_gt0_df.loc[p[0]][c], 2), p[0])\n",
    "    print('Bottom school type', round(grouped_gt0_df.loc[p[1]][c], 2), p[1], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even after adjusting for those measures that aren't 0, for the small number that potentially got added.  The underlying results have not been effected.\n",
    "\n",
    "However these findings are based on mean grouped values.  To get more clarity the next step is to use machine machine learning to cluster the ungrouped data and then look at each cluster group to see the distributions of school types in each group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does appear to be a some kind of link between the type of school and the results of both English Baccalaurete and the older 5+A*-C GCSEs.\n",
    "\n",
    "The correlation between 5+A*-C and the EBacc makes sense because to acheive an eBacc is across a variety of subjects including Maths, English, Sciences, language and history or geography.  Naturally, there will be a correlation between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='machine_learning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"grouped_cluster\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Grouped data Cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at the scatter of some of these different measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress 8 and GCSE results (5+ A*-C)\n",
    "grouped_df.plot(kind='scatter', x='P8MEA', y='PTAC5EM_PTQ_EE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress 8 and ATT8SCR\n",
    "grouped_df.plot(kind='scatter', x='P8MEA', y='ATT8SCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCSE and ATT8SCR\n",
    "grouped_df.plot(kind='scatter', x='PTAC5EM_PTQ_EE', y='ATT8SCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCSE and EBACC results\n",
    "grouped_df.plot(kind='scatter', x='PTAC5EM_PTQ_EE', y='PTEBACC_PTQ_EE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attainment 8 and EBACC results\n",
    "grouped_df.plot(kind='scatter', x='ATT8SCR', y='PTEBACC_PTQ_EE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress 8 and EBACC results\n",
    "grouped_df.plot(kind='scatter', x='P8MEA', y='PTEBACC_PTQ_EE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this investigation I will narrow down the focus of performance measures to a combination of P8 measure and the GCSE.  I have chosen these two because:\n",
    " - Progress 8 - students progress is measured in comparison to other students across the country of similar starting ability, thus it is a good measure for comparing schools\n",
    " - 5+A*-C GCSE inc. Math&Eng - despite being an older measure it is still widely used and understood by everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with I'll follow the steps in the module materials p21.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initial values for k = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialCentroids_df = pd.DataFrame({'P8MEA': [-0.5, 0], \n",
    "                                    'PTAC5EM_PTQ_EE': [18, 30]}, \n",
    "                                   columns=['P8MEA', 'PTAC5EM_PTQ_EE'])\n",
    "\n",
    "initialCentroids_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot these on a scatter plot with the data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(grouped_df['P8MEA'], grouped_df['PTAC5EM_PTQ_EE'])\n",
    "\n",
    "plt.xlabel('Progress 8 measure')\n",
    "plt.ylabel('5+A*-C GCSE')\n",
    "\n",
    "plt.title('School Type KS4 performance 2015-2016 with initial cluster centroids')\n",
    "\n",
    "# Plot the initial centroids:\n",
    "for i in initialCentroids_df.index:\n",
    "    plt.plot(initialCentroids_df.iloc[i]['P8MEA'],\n",
    "             initialCentroids_df.iloc[i]['PTAC5EM_PTQ_EE'],\n",
    "             color='black', marker='x', mew=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise the clustering object\n",
    "kmeans2 = cluster.KMeans(n_clusters=2,\n",
    "                         init=initialCentroids_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the object to the data\n",
    "assignedClusters_clust = kmeans2.fit(grouped_df[['P8MEA', 'PTAC5EM_PTQ_EE']])\n",
    "assignedClusters_clust.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the clustered data along with the final centroids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data points which is in the cluster labelled '0'\n",
    "plt.scatter(grouped_df['P8MEA'][assignedClusters_clust.labels_==0],\n",
    "            grouped_df['PTAC5EM_PTQ_EE'][assignedClusters_clust.labels_==0],\n",
    "            color='red', marker='o', label='cluster 0')\n",
    "\n",
    "# Plot the data points which is in the cluster labelled '1'\n",
    "plt.scatter(grouped_df['P8MEA'][assignedClusters_clust.labels_==1],\n",
    "            grouped_df['PTAC5EM_PTQ_EE'][assignedClusters_clust.labels_==1],\n",
    "            color='blue', marker='o', label='cluster 1')\n",
    "\n",
    "# plot each of the centroids:\n",
    "for (cx, cy) in assignedClusters_clust.cluster_centers_:\n",
    "    plt.plot(cx, cy, color='black', marker='x', mew=2)\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Progress 8 measure')\n",
    "plt.ylabel('5 A*-C GCSE - inc. Math&English')\n",
    "\n",
    "plt.title('School Type KS4 performance 2015-2016 2-means clustering with centroids')\n",
    "\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make generating centroids quicker I'll make a quick function to speed up the process for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# set the seed so that enterpretation of analysis is consitent on each run.\n",
    "random.seed(283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to quickly generate a dataframe \n",
    "# of a given number of random centroidsto speeg\n",
    "def random_centroids(df, x_col, y_col, num_centroids):\n",
    "    \n",
    "    # determine the ranges of the data\n",
    "    x_range = [min(df[x_col]), max(df[y_col])]\n",
    "    y_range = [min(df[x_col]), max(df[y_col])]\n",
    "    \n",
    "    # generate make a collection to store\n",
    "    centroids = collections.defaultdict(list)\n",
    "    \n",
    "    # generate the random values \n",
    "    for i in range(num_centroids):\n",
    "        centroids['X'].append(random.uniform(min(x_range), max(x_range)))\n",
    "        centroids['Y'].append(random.uniform(min(y_range), max(y_range)))\n",
    "    \n",
    "    # return as a dataframe\n",
    "    return pd.DataFrame(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_centroids = random_centroids(grouped_df, 'P8MEA', 'PTAC5EM_PTQ_EE', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a k-means 4 cluster\n",
    "kmeans4 = cluster.KMeans(n_clusters=4, init=initial_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the cluster object to the data\n",
    "assigned_clust = kmeans4.fit(grouped_df[['P8MEA', 'PTAC5EM_PTQ_EE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot clustering results, \n",
    "# colors do not need to be set unless num is greater than 6\n",
    "def plot_cluster(data_x, data_y, assigned_clust, k, \n",
    "                 cluster_labels=None, plt_labels=None, \n",
    "                 plt_title=None, colors=None, save=False):\n",
    "    # set default colors\n",
    "    if colors==None:\n",
    "        colors = sns.palettes.color_palette(n_colors=k)\n",
    "    # set default labels\n",
    "    if cluster_labels==None:\n",
    "        cluster_labels = range(k)\n",
    "    \n",
    "    plt.figure()\n",
    "    # plot the cluster group    \n",
    "    for c in range(k):\n",
    "        plt.scatter(data_x[assigned_clust.labels_==c],\n",
    "                    data_y[assigned_clust.labels_==c],\n",
    "                    color=colors[c], marker='o', label=cluster_labels[c]\n",
    "                   )\n",
    "        \n",
    "    # plot the centroids\n",
    "    for (cx, cy) in assigned_clust.cluster_centers_:\n",
    "        plt.plot(cx, cy, color='black', marker='x', mew=1)\n",
    "    \n",
    "    # prettify it\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.xlabel(plt_labels[0])\n",
    "    plt.ylabel(plt_labels[1])\n",
    "        \n",
    "    plt.title(plt_title)\n",
    "    \n",
    "    # save it out if wanted\n",
    "    if save:\n",
    "        plt.savefig('plot_images/cluster '+ plt_title + ' k='+str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the k-means 4\n",
    "plot_cluster(grouped_df['P8MEA'], grouped_df['PTAC5EM_PTQ_EE'], assigned_clust, 4,\n",
    "             cluster_labels=['a', 'b', 'c', 'd'],\n",
    "             plt_labels=['Progress 8 (Average)', '5+A*-C GCSE (%)'],\n",
    "             plt_title='School Type KS4 performance 2015-2016 \\n4-means clustering with centroids', save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it again to check for variation in clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make another run to see if the groupings vary \n",
    "initial_centroids = random_centroids(grouped_df, 'P8MEA', 'PTAC5EM_PTQ_EE', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a k-means 4 cluster\n",
    "kmeans4 = cluster.KMeans(n_clusters=4, init=initial_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the cluster object to the data\n",
    "assigned_clust = kmeans4.fit(grouped_df[['P8MEA', 'PTAC5EM_PTQ_EE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the k-means 4\n",
    "plot_cluster(grouped_df['P8MEA'], grouped_df['PTAC5EM_PTQ_EE'], assigned_clust, 4,\n",
    "             cluster_labels=['a', 'b', 'c', 'd'],\n",
    "             plt_labels=['Progress 8', '5+A*-C GCSE'],\n",
    "             plt_title='School Type KS4 performance 2015-2016 \\n4-means clustering with centroids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, the error message is indicating that we don't need to declare the centroids.  A quick search online ([stack overflow link](https://stackoverflow.com/questions/28862334/k-means-with-selected-initial-centers)) also explains this.  If we don't pass initial_centroids in then the method will use the default of 10 random iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means 4, third trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise the cluster object\n",
    "kmeans4 = cluster.KMeans(n_clusters=4)\n",
    "\n",
    "# fit the cluster object to the data\n",
    "assigned_clust = kmeans4.fit(grouped_df[['P8MEA', 'PTAC5EM_PTQ_EE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the k-means 4\n",
    "plot_cluster(grouped_df['P8MEA'], grouped_df['PTAC5EM_PTQ_EE'], assigned_clust, 4,\n",
    "             cluster_labels=['a', 'b', 'c', 'd'],\n",
    "             plt_labels=['Progress 8', '5+A*-C GCSE'],\n",
    "             plt_title='School Type KS4 performance 2015-2016 \\n4-means clustering with centroids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variety in the clusterings show that they are unstable I'll try a couple of higher k values to see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise the cluster object\n",
    "kmeans = cluster.KMeans(n_clusters=5)\n",
    "\n",
    "# fit the cluster object to the data\n",
    "assigned_clust = kmeans.fit(grouped_df[['P8MEA', 'PTAC5EM_PTQ_EE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the k-means 5\n",
    "plot_cluster(grouped_df['P8MEA'], grouped_df['PTAC5EM_PTQ_EE'], assigned_clust, 5,\n",
    "             plt_labels=['Progress 8', '5+A*-C GCSE'],\n",
    "             plt_title='School Type KS4 performance 2015-2016 \\n5-means clustering with centroids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise the cluster object\n",
    "kmeans = cluster.KMeans(n_clusters=6)\n",
    "\n",
    "# fit the cluster object to the data\n",
    "assigned_clust = kmeans.fit(grouped_df[['P8MEA', 'PTAC5EM_PTQ_EE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the k-means 6\n",
    "plot_cluster(grouped_df['P8MEA'], grouped_df['PTAC5EM_PTQ_EE'], assigned_clust, 6,\n",
    "             plt_labels=['Progress 8', '5+A*-C GCSE'],\n",
    "             plt_title='School Type KS4 performance 2015-2016 \\n5-means clustering with centroids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are clearly a few ways that this dataset can be clustered.  It is perhaps worth noting that the most of the school types are around the national average measure for Progress8 (0), and above 50% for the GCSE measure.  Their are two clear outliers one at the top right (best score for both GCSE, and progress8) and one at the bottom (second worse GCSE and by far the worse progress8), let's identify which school types they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['P8MEA'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['P8MEA'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['PTAC5EM_PTQ_EE'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['PTAC5EM_PTQ_EE'].idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in both cases the top school type is 'City technology college' and the bottom performer is 'Further Education Sector Institution' \n",
    "\n",
    "How many of each are there in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_results_df[ks4_results_df['NFTYPE']=='CTC']['NFTYPE'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are only 3 schools of that type with results recorded in our cleaned dataset.  What about the 'Further Education Sector Institution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_results_df[ks4_results_df['NFTYPE']=='FESI']['NFTYPE'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 is a few more but still not that many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(round(3/len(ks4_results_df)*100,4), round(12/len(ks4_results_df)*100, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are fractions of a 1 percent of the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"machine_learning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means cluster analysis of the ungrouped dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of the school type distribution in each cluster it will be I need to cluster accross the whole dataset on those performance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_results_df.plot(kind='scatter', x='P8MEA', y='PTAC5EM_PTQ_EE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With there being a range of different measures to look at in combination I will create another helper function to make the process more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to fill out boilerplate code\n",
    "# initialises a kmeans cluster object and fits it to the data\n",
    "# then plots it using the plot_cluster method defined earlier.\n",
    "def kmeans_plot(df, x_column, y_column, k,\n",
    "                cluster_labels=None, plt_labels=None, plt_title=None,\n",
    "                colors=None, initial_centroids=None, save=False\n",
    "                ):\n",
    "    \n",
    "    # create k-means cluster object\n",
    "    if initial_centroids == None:\n",
    "        kmeans_clust = cluster.KMeans(n_clusters=k)\n",
    "    else:\n",
    "        kmeans_clust = cluster.KMeans(n_clusters=k, init=initial_centroids)\n",
    "    # fit the objest to the data\n",
    "    assigned_clust = kmeans_clust.fit(df[[x_column, y_column]])\n",
    "\n",
    "    # plot the kmeans cluster\n",
    "    plot_cluster(df[x_column], df[y_column], assigned_clust, k,\n",
    "                 cluster_labels=cluster_labels, plt_labels=plt_labels,\n",
    "                 plt_title=plt_title, colors=colors, save=save\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have a handy function I can iterate through some different k-values and see which k value fits the data the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Groups of Progress 8 and 5+A*-C measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remind myself of the column names so I can look them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_results_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate with different k values (2 - 8) and plot each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,12):\n",
    "    title = 'KS4 results cluster groups k=' + str(k)\n",
    "    cluster_labels = ['Group ' + str(i) for i in range(k)]\n",
    "    kmeans_plot(ks4_results_df, 'P8MEA', 'PTAC5EM_PTQ_EE', k=k,\n",
    "                plt_title=title, cluster_labels=cluster_labels,\n",
    "                plt_labels=['Progress 8', '%+A*-C GCSE'], save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional clusters seem to break the data into narrow and narrower segments.  But they do appear to be quite spread For our needs I think k=4 is good to look at in more detail.  As I am trying to identify groups that perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS4 results data cluster group plot k=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need a little more control over the plotting so I can move the set the legend position if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'KS4 results cluster groups k=4'\n",
    "\n",
    "kmeans_plot(ks4_results_df, 'P8MEA', 'PTAC5EM_PTQ_EE', k=4,\n",
    "                plt_title=title, cluster_labels=cluster_labels,\n",
    "                plt_labels=['Progress 8', '%+A*-C GCSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to use the filter to separate the data I will need to have access to the cluster object, or supply supply it to the function to be plotted.\n",
    "\n",
    "While editing I'll allow for a little more customisation of the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot clustering results\n",
    "# allows some plot visualisations to be specified\n",
    "def plot_cluster_2(data_x, data_y, assigned_clust, k, \n",
    "                 cluster_labels=None, plt_labels=None, \n",
    "                 plt_title=None, colors=None, legend_loc=None,\n",
    "                 opacity=1, save=False \n",
    "                ):\n",
    "    # set default colors\n",
    "    if colors==None:\n",
    "        colors = sns.palettes.color_palette(n_colors=k)\n",
    "    # set default labels\n",
    "    if cluster_labels==None:\n",
    "        cluster_labels = ['Group ' + str(i) for i in range(k)]\n",
    "    \n",
    "    plt.figure()\n",
    "    # plot the cluster group    \n",
    "    for c in range(k):\n",
    "        plt.scatter(data_x[assigned_clust.labels_==c],\n",
    "                    data_y[assigned_clust.labels_==c],\n",
    "                    color=colors[c], marker='o', \n",
    "                    label=cluster_labels[c],\n",
    "                    alpha=opacity\n",
    "                   )\n",
    "    # plot the centroids\n",
    "    for (cx, cy) in assigned_clust.cluster_centers_:\n",
    "        plt.plot(cx, cy, color='black', marker='x', mew=1)\n",
    "    \n",
    "    # add the legend\n",
    "    plt.legend(loc=legend_loc)\n",
    "        \n",
    "    plt.xlabel(plt_labels[0])\n",
    "    plt.ylabel(plt_labels[1])\n",
    "        \n",
    "    plt.title(plt_title)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('plot_images/cluster '+ plt_title + ' k='+str(k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can create a cluster group and then use it to plot the groups and then filter the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the title I want to use\n",
    "title = 'KS4 results kMeans4 - PMEA GCSE'\n",
    "\n",
    "# so that it always runs the same I need to initialise centroids in this case\n",
    "init_centroids = pd.DataFrame({'PMEA': [-1.5, -0.5, 0, 0.75],\n",
    "                                'PTAC5EM_PTQ_EE': [0.2, 0.4, 0.6, 0.8]},\n",
    "                              columns=['PMEA', 'PTAC5EM_PTQ_EE'])\n",
    "\n",
    "# initialise the kmeans cluster\n",
    "kmeans_4 = cluster.KMeans(n_clusters=4, init=init_centroids)\n",
    "# initialise the kmeans cluster\n",
    "\n",
    "# fit it to the data\n",
    "assigned_clusters = kmeans4.fit(ks4_results_df[['P8MEA', 'PTAC5EM_PTQ_EE']])\n",
    "\n",
    "# plot the results\n",
    "plot_cluster_2(ks4_results_df['P8MEA'], ks4_results_df['PTAC5EM_PTQ_EE'], \n",
    "               assigned_clust=assigned_clusters, k=4,\n",
    "            plt_title=title,\n",
    "            plt_labels=['Progress 8', 'Students to acheive +A*-C GCSE (%)'],\n",
    "            legend_loc=(1.05, 0.5),\n",
    "            opacity=0.7,\n",
    "            save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters appear to be separated into groups around the result bands.  With the progress measure having a strong impact on the groupings.  However, they look quite wide ranging.  I'll run a silouette analysis on them to see whether they are suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='silhouette'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhouette coefficients analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans=4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a column on the results data for each value\n",
    "ks4_results_df['cluster'] = pd.Series(assigned_clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it looks ok.\n",
    "ks4_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the silhouette coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from notebook 21.3\n",
    "# Add the silhouette coefficients as a new column in the\n",
    "# ks4_results_df:\n",
    "ks4_results_df['silhouette'] = silhouette_samples(ks4_results_df[['P8MEA', 'PTAC5EM_PTQ_EE']],\n",
    "                                                             np.array(ks4_results_df['cluster']))\n",
    "\n",
    "ks4_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe so we can see a curve\n",
    "silhouette_plot_data_df = ks4_results_df.sort_values(['cluster', 'silhouette'])\n",
    "silhouette_plot_data_df.index = list(range(len(silhouette_plot_data_df)))\n",
    "\n",
    "# set the colours\n",
    "colours = sns.palettes.color_palette(n_colors=len(set(ks4_results_df['cluster'])))\n",
    "\n",
    "for clust in set(silhouette_plot_data_df['cluster']):\n",
    "    plt.bar(silhouette_plot_data_df[silhouette_plot_data_df['cluster']==clust].index,\n",
    "            silhouette_plot_data_df[silhouette_plot_data_df['cluster']==clust]['silhouette'],\n",
    "            color=colours[clust], alpha=0.7, label='Cluster ' + str(clust))\n",
    "    \n",
    "plt.title('kMeans=4 Silhouette plot of Progress 8 and GCSE A*-C')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Number of data point')\n",
    "plt.ylabel('Silhouette coefficient')\n",
    "\n",
    "plt.savefig('plot_images/silhouette_k4_P8_AC5.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This silhouette plot shows us clearly that the clusters are uneven in size, with a wide range of coefficiets.  there are ales a few overlapping points showing.\n",
    "\n",
    "I'll repeat using a higher k-value the above steps using a higher k value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS4 results data cluster group plot k=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll drop the extra columns created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop the added columns\n",
    "if 'cluster' in ks4_results_df.columns:\n",
    "    ks4_results_df.drop(['cluster', 'silhouette'], axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the title I want to use\n",
    "title = 'KS4 results cluster groups k=9'\n",
    "\n",
    "# so that it always runs the same I need to initialise centroids in this case\n",
    "init_centroids_9 = pd.DataFrame({'PMEA': [-2, -1.5, -1, -0.75, -0.5, -0.25, 0, 0.25,  0.75],\n",
    "                                'PTAC5EM_PTQ_EE': [0.2, 0.3, 0.4, 0.5, 0.55, 0.6, 0.7, 0.8, 0.9]},\n",
    "                              columns=['PMEA', 'PTAC5EM_PTQ_EE'])\n",
    "\n",
    "# initialise the kmeans cluster\n",
    "kmeans9 = cluster.KMeans(n_clusters=9, init=init_centroids_9, n_init=1)\n",
    "\n",
    "# fit it to the data\n",
    "assigned_clusters_9 = kmeans9.fit(ks4_results_df[['P8MEA', 'PTAC5EM_PTQ_EE']])\n",
    "\n",
    "# plot the results\n",
    "plot_cluster_2(ks4_results_df['P8MEA'], ks4_results_df['PTAC5EM_PTQ_EE'], \n",
    "               assigned_clust=assigned_clusters_9, k=9,\n",
    "            plt_title=title,\n",
    "            plt_labels=['Progress 8', 'Students to acheive +A*-C GCSE (%)'],\n",
    "            legend_loc=(1.05, 0.5),\n",
    "            opacity=0.7,\n",
    "            save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters still look quite wide ranging.  I'll run a silouette analysis on them to see if the higher k value has evened things out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette analysis of kMeans 9 clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a column on the results data for each value\n",
    "ks4_results_df['cluster'] = pd.Series(assigned_clusters_9.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the silhouette coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from notebook 21.3\n",
    "# Add the silhouette coefficients as a new column in the\n",
    "# ks4_results_df:\n",
    "ks4_results_df['silhouette'] = silhouette_samples(ks4_results_df[['P8MEA', 'PTAC5EM_PTQ_EE']],\n",
    "                                                             np.array(ks4_results_df['cluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe so we can see a curve\n",
    "silhouette_plot_data_df = ks4_results_df.sort_values(['cluster', 'silhouette'])\n",
    "silhouette_plot_data_df.index = list(range(len(silhouette_plot_data_df)))\n",
    "\n",
    "colours = sns.palettes.color_palette(n_colors=len(set(ks4_results_df['cluster'])))\n",
    "\n",
    "for clust in set(silhouette_plot_data_df['cluster']):\n",
    "    plt.bar(silhouette_plot_data_df[silhouette_plot_data_df['cluster']==clust].index,\n",
    "            silhouette_plot_data_df[silhouette_plot_data_df['cluster']==clust]['silhouette'],\n",
    "            color=colours[clust], alpha=0.7, label='Cluster ' + str(clust))\n",
    "    \n",
    "plt.title('kMeans=9 Silhouette plot of Progress 8 and GCSE A*-C')\n",
    "plt.legend(loc=(1.05,0.8))\n",
    "\n",
    "plt.xlabel('Number of data point')\n",
    "plt.ylabel('Silhouette coefficient')\n",
    "\n",
    "plt.savefig('plot_images/silhouette_k9_P8_AC5.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no real improvement on the silhouette coefficients and there are still some overlapping groups.  This isn't the grouping I was hoping for to help me clarify the performance measures. \n",
    "\n",
    "But it has enabled me to gain a better insight to the spread of the data. I'll take a look at the Attainment 8 and GCSE 5+A*-C now in case it is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=ks4_results_df['ATT8SCR'], y=ks4_results_df['PTAC5EM_PTQ_EE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatter is a little less spread.  It may give a better range of values and is a good measure of the final results KS4 students achieve.\n",
    "\n",
    "So our new measures will be:\n",
    " - Attainment 8\n",
    " - GCSE 5+ A*-C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Groups of Attainment 8 and the GCSE 5+ A*-C measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the added columns\n",
    "if 'cluster' in ks4_results_df.columns:\n",
    "    ks4_results_df.drop(['cluster', 'silhouette'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_results_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate with different k values (2 - 8) and plot each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,12):\n",
    "    title = 'KS4 results cluster groups k=' + str(k)\n",
    "    cluster_labels = ['Group ' + str(i) for i in range(k)]\n",
    "    kmeans_plot(ks4_results_df, 'ATT8SCR', 'PTAC5EM_PTQ_EE', k=k,\n",
    "                plt_title=title, cluster_labels=cluster_labels,\n",
    "                plt_labels=['Attainment 8', 'English GCSE 5+ A*-C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again these are all quite spread out with values ranging quite a lot from one cluster to another, making it hard to use as ameasure for school types. I'll try a very high k value of 11 kmeans.  I'll quickly run the silouette tests again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans clustering of Attainment 8 and GCSE 5+ A*-C results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colour_map = sns.palettes.color_palette(n_colors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the title I want to use\n",
    "title = 'KS4 (ATT8 GCSE) cluster groups k=5'\n",
    "\n",
    "# so that it always runs the same I need to initialise centroids in this case\n",
    "init_centroids = pd.DataFrame({'ATT8SCR': [0.2, 0.4, 0.5, 0.6, 0.8],\n",
    "                                'PTAC5EM_PTQ_EE': [30, 45, 50, 55, 60]},\n",
    "                              columns=['ATT8SCR', 'PTAC5EM_PTQ_EE'])\n",
    "\n",
    "# initialise the kmeans cluster\n",
    "kmeans5 = cluster.KMeans(n_clusters=5, init=init_centroids, n_init=1)\n",
    "\n",
    "# fit it to the data\n",
    "assigned_clusters = kmeans5.fit(ks4_results_df[['ATT8SCR', 'PTAC5EM_PTQ_EE']])\n",
    "\n",
    "# plot the results\n",
    "plot_cluster_2(ks4_results_df['ATT8SCR'], ks4_results_df['PTAC5EM_PTQ_EE'], \n",
    "               assigned_clust=assigned_clusters, k=5,\n",
    "               plt_title=title,\n",
    "               plt_labels=['Attainment 8', '%+A*-C GCSE'],\n",
    "               legend_loc=(0.02, 0.8),\n",
    "               colors=colour_map,\n",
    "               opacity=0.7,\n",
    "               save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the clusters appear to be separated into groups around the result bands. The range of values looks slightly less than with the P8Measure we looked at earlier.  I'll run a silouette analysis on them to see whether they are suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette analysis of kMeans 5 clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a column on the results data for each value\n",
    "ks4_results_df['cluster'] = pd.Series(assigned_clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it looks ok.\n",
    "ks4_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the silhouette coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from notebook 21.3\n",
    "# Add the silhouette coefficients as a new column in the\n",
    "# ks4_results_df:\n",
    "ks4_results_df['silhouette'] = silhouette_samples(ks4_results_df[['ATT8SCR', 'PTAC5EM_PTQ_EE']],\n",
    "                                                             np.array(ks4_results_df['cluster']))\n",
    "\n",
    "ks4_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe so we can see a curve\n",
    "silhouette_plot_data_df = ks4_results_df.sort_values(['cluster', 'silhouette'])\n",
    "silhouette_plot_data_df.index = list(range(len(silhouette_plot_data_df)))\n",
    "\n",
    "\n",
    "for clust in set(silhouette_plot_data_df['cluster']):\n",
    "    plt.bar(silhouette_plot_data_df[silhouette_plot_data_df['cluster']==clust].index,\n",
    "            silhouette_plot_data_df[silhouette_plot_data_df['cluster']==clust]['silhouette'],\n",
    "            color=colour_map[clust], alpha=0.7, label='Cluster ' + str(clust))\n",
    "    \n",
    "plt.title('Silhouette plot of Attainment 8 and GCSE dataset')\n",
    "plt.legend(loc=(1, 0.5))\n",
    "\n",
    "plt.xlabel('Number of data point')\n",
    "plt.ylabel('Silhouette coefficient')\n",
    "\n",
    "plt.savefig('plot_images/silhouette_k9_A8_AC5.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These clusters look to have less crossover which is good as I can't see any negative values.  However, the range of silhouette values is still extremely wide.  So it makes it hard to see this as being a useful grouping to divide the dataset into performance.\n",
    "\n",
    "I will use it to double check the school types quicky though.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cluster groupings indicate that there is probably some spread in the data.  I'm going to go back to the dataframe and plot out the performance measures and colour code it by school type to see how they lie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"school_scatter\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Scatter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a list of the school types and assign each a colour\n",
    "school_code = list(set(ks4_results_df['NFTYPE']))\n",
    "\n",
    "# # Make a colour map for each school type\n",
    "# colour_map = sns.palettes.color_palette('paired', n_colors=len(school_code))\n",
    "\n",
    "colour_map = sns.palettes.color_palette(palette='Paired', n_colors=12)\n",
    "\n",
    "# add the colour column to the dataframe \n",
    "ks4_results_df['colour'] = ks4_results_df['NFTYPE'].apply(lambda x:colour_map[school_code.index(x)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot them all to the same plot\n",
    "ks4_results_df.plot.scatter(x='ATT8SCR', y='PTAC5EM_PTQ_EE',\n",
    "                            s=30,\n",
    "                            c=ks4_results_df['colour']\n",
    "                           )\n",
    "\n",
    "# add the title and axis labels\n",
    "plt.title('Scatter plot of pupils KS4 results per school')\n",
    "plt.xlabel('Average Attainment 8 Score')\n",
    "plt.ylabel('5+A*-C GCSE including English and Maths (%))')\n",
    "\n",
    "# add a legend to the scatter plot\n",
    "import matplotlib.patches as mpatches\n",
    "# make the legend handles\n",
    "legend_handles = ([mpatches.Patch(color=colour_map[0], label=nftypes[school_code[0]])]+\n",
    "                  [mpatches.Patch(color=colour_map[1], label=nftypes[school_code[1]])]+\n",
    "                  [mpatches.Patch(color=colour_map[2], label=nftypes[school_code[2]])]+\n",
    "                  [mpatches.Patch(color=colour_map[3], label=nftypes[school_code[3]])]+\n",
    "                  [mpatches.Patch(color=colour_map[4], label=nftypes[school_code[4]])]+\n",
    "                  [mpatches.Patch(color=colour_map[5], label=nftypes[school_code[5]])]+\n",
    "                  [mpatches.Patch(color=colour_map[6], label=nftypes[school_code[6]])]+\n",
    "                  [mpatches.Patch(color=colour_map[7], label=nftypes[school_code[7]])]+\n",
    "                  [mpatches.Patch(color=colour_map[8], label=nftypes[school_code[8]])]+\n",
    "                  [mpatches.Patch(color=colour_map[9], label=nftypes[school_code[9]])]+\n",
    "                  [mpatches.Patch(color=colour_map[10], label=nftypes[school_code[10]])])\n",
    "                \n",
    "plt.legend(handles=legend_handles, loc=(0.05, 0.4))\n",
    "\n",
    "plt.savefig('plot_images/scatter_schools_distribution_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to plot each school type to see it's distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snippet from https://stackoverflow.com/questions/3899980/how-to-change-the-font-size-on-a-matplotlib-plot\n",
    "for school in school_code:\n",
    "    \n",
    "    subset = ks4_results_df[ks4_results_df['NFTYPE']==school]\n",
    "    # plot only that school type\n",
    "    subset.plot.scatter(x='ATT8SCR', y='PTAC5EM_PTQ_EE',\n",
    "                        c=subset['colour'],\n",
    "                        s=30\n",
    "                       )\n",
    "    # add the title and axis labels\n",
    "    plt.title('School type: ' + nftypes[school])\n",
    "    plt.xlabel('Average Attainment 8 Score')\n",
    "    plt.ylabel('5+A*-C GCSE including English and Maths (%))')\n",
    "    \n",
    "    \n",
    "    plt.savefig('plot_images/scatter_' + school + '_dist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='q1_findings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Q1: Findings\n",
    "\n",
    "Observations.  The mean value of the grouped schools performance can be misleading.  The spread within each school types results, and the variance in number makes it hard to be confident in saying there is a link between school type and performance in the measures investigated.\n",
    "\n",
    "When the data is grouped by school type with mean values for each measure there are two clear outliers, CTC as the top performer in all and FESI as the worst performer in all measures.  However, when we run cluster analysis and silhouette plots we see how spread the data is for each type.  Looking at each scatter on a by school basis revealed that CTC had 2 schools at the top and 1 at the bottom (of 3 schools), whereas FESI had a more even spread of data points.\n",
    "\n",
    "In balance I would say that although the mean of the performance measures suggest there could be a link.  Further investigation suggests that the spread of the data does not reflect such a narrow grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"q2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  Q2 - Keystage 2 and 4 Investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do schools that perform well at KS2 deliver as good or better results at KS4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many mainstream schools are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2.find({'RECTYPE': 1}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are a very large number of documents in the dataset (after taking out the non-mainstream schools).  Which schools are in both ks2 and ks4?  I seem to remember there being a flag in the KS4 database if the school had published KS2 results.\n",
    "\n",
    "<a name=\"joining\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print keys with key stage 2 in the description\n",
    "for k in ks4_expanded_name.keys():\n",
    "    if 'key stage 2' in ks4_expanded_name[k].lower():\n",
    "        print(k, ks4_expanded_name[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found it, so it is the TABKS2.  Let me make a dataframe of just those schools from KS4 then I can use the URN to look up the KS2 ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_schools_df = pd.DataFrame(list(ks4.find({'TABKS2': 1},\n",
    "                                            {'URN': 1,\n",
    "                                             'NFTYPE': 1,\n",
    "                                             'PTAC5EM_PTQ_EE': 1,\n",
    "                                             'PTEBACC_PTQ_EE': 1,\n",
    "                                             'P8MEA': 1,\n",
    "                                             'ATT8SCR': 1,\n",
    "                                             '_id': 0\n",
    "                                            })))\n",
    "len(ks4_schools_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_schools_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the missing values\n",
    "ks4_schools_df.dropna(inplace=True)\n",
    "\n",
    "ks4_schools_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is there a similar key in the ks2 dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ks2_expanded_name.keys():\n",
    "    if 'key stage 4' in ks2_expanded_name[k].lower():\n",
    "        print(k, ks2_expanded_name[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome there is!  I can then use that to grab the schools from ks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_schools_df = pd.DataFrame(list(ks2.find({'TAB15': 1})))\n",
    "len(ks2_schools_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 isn't really that many, and looking at the style of the label code it probably means included in 2015 only.  Perhaps I can look up by the URN and match to those from the ks4 schools dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks4_schools_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks4_schools_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_schools_2_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for index, row in ks4_schools_df.iterrows():\n",
    "    doc = ks2.find_one({'URN': row['URN']},\n",
    "                       {'URN': 1,\n",
    "                        'PTGPS_HIGH_H': 1,\n",
    "                        'PTMAT_HIGH': 1,\n",
    "                        'PTREAD_HIGH': 1,\n",
    "                        'PTRWM_HIGH': 1,\n",
    "                        'PTGPS_EXP': 1,\n",
    "                        'PTMAT_EXP':1,\n",
    "                        'PTREAD_EXP':1,\n",
    "                        'PTRWM_EXP':1,\n",
    "                        '_id': 0 })\n",
    "    ks2_schools_2_df.append(list(doc))\n",
    "    \n",
    "#     print(row['URN'], doc['URN'])\n",
    "    \n",
    "ks2_schools_2_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't really work that well.  Let's try another way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a list of all the URN\n",
    "urn_list = list(ks4_schools_df['URN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the keys in each doc of ks2.  \n",
    "for doc in ks2.find():\n",
    "    for key in list(doc.keys()):\n",
    "        # find the URN key\n",
    "        if key == 'URN':\n",
    "            # checks against our list\n",
    "            if int(doc[key]) in urn_list:\n",
    "                # if matches it adds a new key to tag the schools that are in ks4 too\n",
    "                ks2.update_one({'_id': doc['_id']},\n",
    "                               {'$set': {'school_in_ks4': 1}})\n",
    "\n",
    "ks2.find_one({'school_in_ks4':1})\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "great that worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "great now we can grab those data and put them it a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks2_schools_df = pd.DataFrame(list(ks2.find({'school_in_ks4': 1},\n",
    "                                            {'URN': 1,\n",
    "                                             'PTGPS_HIGH': 1,\n",
    "                                             'PTMAT_HIGH': 1,\n",
    "                                             'PTREAD_HIGH': 1,\n",
    "                                             'PTRWM_HIGH': 1,\n",
    "                                             'PTGPS_EXP': 1,\n",
    "                                             'PTMAT_EXP': 1,\n",
    "                                             'PTREAD_EXP': 1,\n",
    "                                             'PTRWM_EXP': 1,\n",
    "                                             \n",
    "                                             '_id': 0 })))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ks2_schools_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_schools_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_schools_df['URN'] = ks2_schools_df['URN'].apply(lambda x: int(x))\n",
    "ks2_schools_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get an idea of the data\n",
    "ks2_schools_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_schools_df.drop('URN', axis=1).plot(kind='bar', subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge the two dataframes\n",
    "ks2_ks4_df = pd.merge(ks4_schools_df, ks2_schools_df, on='URN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_ks4_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_ks4_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_by_mean = ks2_ks4_df.drop('URN', axis=1).groupby('NFTYPE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_mean.sort_values('PTAC5EM_PTQ_EE').plot(kind='bar', subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_mean.plot.scatter(x='ATT8SCR', y='PTRWM_HIGH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_mean.plot.scatter(x='ATT8SCR', y='PTRWM_EXP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the values of high grades of PTRWM and attainment 8\n",
    "ks2_ks4_df[['ATT8SCR', 'PTRWM_HIGH', ]].plot.scatter(x='ATT8SCR',y='PTRWM_HIGH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the values of expected PTRWM and attainment 8\n",
    "ks2_ks4_df[['ATT8SCR', 'PTRWM_EXP']].plot.scatter(x='ATT8SCR',y='PTRWM_EXP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='plotting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting KS2 - KS4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the expected level performance vs Attainment 8 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset the data\n",
    "scatter_df = ks2_ks4_df[['ATT8SCR', 'PTRWM_EXP', 'NFTYPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the color map and school codes\n",
    "# get a list of the school types and assign each a colour\n",
    "school_code = list(set(scatter_df['NFTYPE']))\n",
    "\n",
    "colour_map = sns.palettes.color_palette(palette='Paired', n_colors=len(school_code))\n",
    "\n",
    "school_code.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the colour column to the dataframe \n",
    "scatter_df['colour'] = scatter_df['NFTYPE'].apply(lambda x:colour_map[school_code.index(x)])\n",
    "\n",
    "\n",
    "# plot them all to the same plot\n",
    "scatter_df.plot.scatter(x='ATT8SCR', y='PTRWM_EXP',\n",
    "                            s=30,\n",
    "                            c=scatter_df['colour']\n",
    "                           )\n",
    "\n",
    "\n",
    "# add the title and labels\n",
    "plt.title('Schools student performance KS2 and KS4')\n",
    "plt.xlabel('Average Attainment 8 Score at KS4')\n",
    "plt.ylabel('% Expected Level in Reading,\\nWriting and Mathematics at KS2')\n",
    "\n",
    "# make the legend handles\n",
    "legend_handles = ([mpatches.Patch(color=colour_map[0], label=nftypes[school_code[0]])]+\n",
    "                  [mpatches.Patch(color=colour_map[1], label=nftypes[school_code[1]])]+\n",
    "                  [mpatches.Patch(color=colour_map[2], label=nftypes[school_code[2]])]+\n",
    "                  [mpatches.Patch(color=colour_map[3], label=nftypes[school_code[3]])]+\n",
    "                  [mpatches.Patch(color=colour_map[4], label=nftypes[school_code[4]])]+\n",
    "                  [mpatches.Patch(color=colour_map[5], label=nftypes[school_code[5]])]+\n",
    "                  [mpatches.Patch(color=colour_map[6], label=nftypes[school_code[6]])])\n",
    "                \n",
    "plt.legend(handles=legend_handles, loc=(0.05, 0.75))\n",
    "\n",
    "plt.savefig('plot_images/KS2_KS4_EXP_ATT8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the High level performance vs Attainment 8 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset the data\n",
    "scatter_df = ks2_ks4_df[['ATT8SCR', 'PTRWM_HIGH', 'NFTYPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the color map and school codes\n",
    "# get a list of the school types and assign each a colour\n",
    "school_code = list(set(scatter_df['NFTYPE']))\n",
    "\n",
    "colour_map = sns.palettes.color_palette(palette='Paired', n_colors=len(school_code))\n",
    "\n",
    "school_code.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the colour column to the dataframe \n",
    "scatter_df['colour'] = scatter_df['NFTYPE'].apply(lambda x:colour_map[school_code.index(x)])\n",
    "\n",
    "\n",
    "# plot them all to the same plot\n",
    "scatter_df.plot.scatter(x='ATT8SCR', y='PTRWM_HIGH',\n",
    "                            s=30,\n",
    "                            c=scatter_df['colour']\n",
    "                           )\n",
    "\n",
    "# add the title and axis labels\n",
    "plt.title('Schools student performance KS2 and KS4')\n",
    "plt.xlabel('Average Attainment 8 Score at KS4')\n",
    "plt.ylabel('% High Level in Reading,\\nWriting and Mathematics at KS2')\n",
    "\n",
    "# make the legend handles\n",
    "legend_handles = ([mpatches.Patch(color=colour_map[0], label=nftypes[school_code[0]])]+\n",
    "                  [mpatches.Patch(color=colour_map[1], label=nftypes[school_code[1]])]+\n",
    "                  [mpatches.Patch(color=colour_map[2], label=nftypes[school_code[2]])]+\n",
    "                  [mpatches.Patch(color=colour_map[3], label=nftypes[school_code[3]])]+\n",
    "                  [mpatches.Patch(color=colour_map[4], label=nftypes[school_code[4]])]+\n",
    "                  [mpatches.Patch(color=colour_map[5], label=nftypes[school_code[5]])]+\n",
    "                  [mpatches.Patch(color=colour_map[6], label=nftypes[school_code[6]])])\n",
    "                \n",
    "plt.legend(handles=legend_handles, loc=(0.05, 0.75))\n",
    "\n",
    "plt.savefig('plot_images/KS2_KS4_HIGH_ATT8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='pearson'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the High level performance vs GCSE 5 A*-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset the data\n",
    "scatter_df = ks2_ks4_df[['PTAC5EM_PTQ_EE', 'PTRWM_HIGH', 'NFTYPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the color map and school codes\n",
    "# get a list of the school types and assign each a colour\n",
    "school_code = list(set(scatter_df['NFTYPE']))\n",
    "\n",
    "colour_map = sns.palettes.color_palette(palette='Paired', n_colors=len(school_code))\n",
    "\n",
    "school_code.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the colour column to the dataframe \n",
    "scatter_df['colour'] = scatter_df['NFTYPE'].apply(lambda x:colour_map[school_code.index(x)])\n",
    "\n",
    "\n",
    "# plot them all to the same plot\n",
    "scatter_df.plot.scatter(x='PTAC5EM_PTQ_EE', y='PTRWM_HIGH',\n",
    "                            s=30,\n",
    "                            c=scatter_df['colour']\n",
    "                           )\n",
    "\n",
    "# add the title and axis labels\n",
    "plt.title('Schools student performance KS2 and KS4')\n",
    "plt.xlabel('% Students to acheive 5+ A*-C at GCSE')\n",
    "plt.ylabel('% High Level in Reading,\\nWriting and Mathematics at KS2')\n",
    "\n",
    "# make the legend handles\n",
    "legend_handles = ([mpatches.Patch(color=colour_map[0], label=nftypes[school_code[0]])]+\n",
    "                  [mpatches.Patch(color=colour_map[1], label=nftypes[school_code[1]])]+\n",
    "                  [mpatches.Patch(color=colour_map[2], label=nftypes[school_code[2]])]+\n",
    "                  [mpatches.Patch(color=colour_map[3], label=nftypes[school_code[3]])]+\n",
    "                  [mpatches.Patch(color=colour_map[4], label=nftypes[school_code[4]])]+\n",
    "                  [mpatches.Patch(color=colour_map[5], label=nftypes[school_code[5]])]+\n",
    "                  [mpatches.Patch(color=colour_map[6], label=nftypes[school_code[6]])])\n",
    "                \n",
    "plt.legend(handles=legend_handles, loc=(0.05, 0.75))\n",
    "\n",
    "plt.savefig('plot_images/KS2_KS4_HIGH_AC5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the High level performance vs GCSE 5 A*-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset the data\n",
    "scatter_df = ks2_ks4_df[['PTAC5EM_PTQ_EE', 'PTRWM_EXP', 'NFTYPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the color map and school codes\n",
    "# get a list of the school types and assign each a colour\n",
    "school_code = list(set(scatter_df['NFTYPE']))\n",
    "\n",
    "colour_map = sns.palettes.color_palette(palette='Paired', n_colors=len(school_code))\n",
    "\n",
    "school_code.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the colour column to the dataframe \n",
    "scatter_df['colour'] = scatter_df['NFTYPE'].apply(lambda x:colour_map[school_code.index(x)])\n",
    "\n",
    "\n",
    "# plot them all to the same plot\n",
    "scatter_df.plot.scatter(x='PTAC5EM_PTQ_EE', y='PTRWM_EXP',\n",
    "                            s=30,\n",
    "                            c=scatter_df['colour']\n",
    "                           )\n",
    "\n",
    "# add the title and axis labels\n",
    "plt.title('Schools student performance KS2 and KS4')\n",
    "plt.xlabel('% Students to acheive 5+ A*-C at GCSE')\n",
    "plt.ylabel('% Expected Level in Reading,\\nWriting and Mathematics at KS2')\n",
    "\n",
    "# make the legend handles\n",
    "legend_handles = ([mpatches.Patch(color=colour_map[0], label=nftypes[school_code[0]])]+\n",
    "                  [mpatches.Patch(color=colour_map[1], label=nftypes[school_code[1]])]+\n",
    "                  [mpatches.Patch(color=colour_map[2], label=nftypes[school_code[2]])]+\n",
    "                  [mpatches.Patch(color=colour_map[3], label=nftypes[school_code[3]])]+\n",
    "                  [mpatches.Patch(color=colour_map[4], label=nftypes[school_code[4]])]+\n",
    "                  [mpatches.Patch(color=colour_map[5], label=nftypes[school_code[5]])]+\n",
    "                  [mpatches.Patch(color=colour_map[6], label=nftypes[school_code[6]])])\n",
    "                \n",
    "plt.legend(handles=legend_handles, loc=(0.05, 0.75))\n",
    "\n",
    "plt.savefig('plot_images/KS2_KS4_EXP_AC5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='pearson'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson's *R*² test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attainment 8 and high KS2\n",
    "a = scipy.stats.pearsonr(ks2_ks4_df['PTRWM_HIGH'],\n",
    "                     ks2_ks4_df['ATT8SCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attainment 8 and Expected KS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = scipy.stats.pearsonr(ks2_ks4_df['ATT8SCR'],\n",
    "                     ks2_ks4_df['PTRWM_EXP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5+ A*-C and high KS2\n",
    "c = scipy.stats.pearsonr(ks2_ks4_df['PTAC5EM_PTQ_EE'],\n",
    "                     ks2_ks4_df['PTRWM_HIGH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5+ A*-C and Expected KS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = scipy.stats.pearsonr(ks2_ks4_df['PTAC5EM_PTQ_EE'],\n",
    "                     ks2_ks4_df['PTRWM_EXP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'R2 value': [a[0], b[0], c[0], d[0]], 'P value': [a[1], b[1], c[1], d[1]],\n",
    " 'Comparison': ['A8 to High KS2', 'A8 to Exp KS2', 'AC5 to High KS2', 'AC5 to EXP KS2']})\n",
    "# results.set_index('Comparison')\n",
    "# results[['R2 value', 'P value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.set_index('Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Observations,  these statistics suggest that there is a slight positive correlation between students that achieve high scores at KS2 in Reading, Writing and Mathematics with Achieving better results at KS4 in both of the Attainment 8 scores and 5+A*-C GCSE grades.\n",
    "\n",
    "Both have a very small _p_ value and so we can say that the result is significant.  We can therefore reject the null hypothesis that high performing schools perform the same as any other at KS4 (for the measures tested at least).\n",
    "\n",
    "We can also see that the achievement of only the expected level of KS2 standard in Reading, Writing and Mathematics were not as correlated (the R value is smaller (between 15.5 and 17.3) and the _p_ value is too high for this result to be deemed significant (it should be under 0.05) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='q1_findings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis suggests that schools whose students achieve high scores at KS2 in Reading writing and Maths are also schools that achieved better results at KS4.  However it is not a massive amount higher and the dataset used did not have a large number of schools that were in both KS2 and KS4 published.  Therefore, there can be a number of confounding factors, which will be ellucidated in the accompanying report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup/remove the database\n",
    "<a name=\"cleanup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the lines below to remove the MongoDB created in the investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to remove the database if needed\n",
    "client.drop_database('schools_db')\n",
    "client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
