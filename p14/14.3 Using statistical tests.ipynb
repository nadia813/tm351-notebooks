{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using statistical tests\n",
    "This Notebook will show some examples of using statistical tests to get qualitative results from questions asked of the accidents dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "\n",
    "import pymongo\n",
    "import datetime\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open a connection to the Mongo server, open the accidents database and name the collections of accidents and labels\n",
    "# client = pymongo.MongoClient('mongodb://localhost:27017/')\n",
    "client = pymongo.MongoClient('mongodb://localhost:27351/')\n",
    "\n",
    "db = client.accidents\n",
    "accidents = db.accidents\n",
    "labels = db.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the expanded names of keys and human-readable codes into memory\n",
    "\n",
    "expanded_name = collections.defaultdict(str)\n",
    "for e in labels.find({'expanded': {\"$exists\": True}}):\n",
    "    expanded_name[e['label']] = e['expanded']\n",
    "    \n",
    "label_of = collections.defaultdict(str)\n",
    "for l in labels.find({'codes': {\"$exists\": True}}):\n",
    "    for c in l['codes']:\n",
    "        try:\n",
    "            label_of[l['label'], int(c)] = l['codes'][c]\n",
    "        except ValueError: \n",
    "            label_of[l['label'], c] = l['codes'][c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's *R*²\n",
    "### Comparing the number of casualties and vehicles\n",
    "This is the same investigation as in Notebook `14.2 Introduction to accidents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a DataFrame, one row for each accident\n",
    "cas_veh_unrolled_df = pd.DataFrame(list(accidents.find({}, ['Number_of_Casualties', 'Number_of_Vehicles'])))\n",
    "\n",
    "# Count the number of each severity\n",
    "cas_veh_df = pd.crosstab(cas_veh_unrolled_df['Number_of_Casualties'], \n",
    "                                      cas_veh_unrolled_df['Number_of_Vehicles'])\n",
    "# Reshape\n",
    "cas_veh_long_df = cas_veh_df.stack().reset_index()\n",
    "cas_veh_long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressionline = scipy.stats.linregress(cas_veh_unrolled_df['Number_of_Casualties'],\n",
    "                                       cas_veh_unrolled_df['Number_of_Vehicles'])\n",
    "\n",
    "# The regression line is of the form y = m x + b\n",
    "m = regressionline[0]\n",
    "b = regressionline[1]\n",
    "(m, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(cas_veh_long_df['Number_of_Casualties'], \n",
    "            cas_veh_long_df['Number_of_Vehicles'],\n",
    "            s=np.sqrt(cas_veh_long_df[0])*1.5,\n",
    "            alpha=0.5\n",
    "            )\n",
    "\n",
    "x = np.linspace(0, 30, 20)\n",
    "plt.plot(x, m*x + b)\n",
    "\n",
    "plt.xlabel('Number of casualties')\n",
    "plt.ylabel('Number of vehicles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pearsonr` function calculates Pearson's *R*² value of correlation. The function takes two lists of numbers, of equal lengths. The Pearson's *R*² function looks at the values at the same index in both lists and finds how the values in one column vary with respect to the other column. \n",
    "\n",
    "Note that we have to give each accident on its own row: if there are 145,000 accidents, the `pearsonr` function must be passed lists with 145,000 items.\n",
    "\n",
    "Recall that values near +1 show good positive correlation, values near -1 show good negative correlation, and values near 0 show no particular correlation. The `scipy` function returns a second value, the *p* value of the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(cas_veh_unrolled_df['Number_of_Casualties'], \n",
    "                     cas_veh_unrolled_df['Number_of_Vehicles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows a small, positive correlation with a very small *p* value. In other words, there's not much correlation, and the result is statistically significant. This means we can reject the the null hypothesis that the number of casualties in an accident is unrelated to the number of vehicles.\n",
    "\n",
    "Looking at the data, it seems to be a result that most accidents result in very few casualties, and the accidents with the most casualties have few vehicles.\n",
    "\n",
    "Can you think of a reason for this?\n",
    "\n",
    "You'll look at this in more detail in Notebook `14.4 Regression on subgroups`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activityAns"
   },
   "source": [
    "### Activity 1\n",
    "Ages of people in the accidents dataset are stored as bands, not continuous values. This means that correlations between them must use Spearman's *r*.\n",
    "\n",
    "Calculate the Spearman rank-order correlation coefficient between the age of a vehicle's driver and the age of the passengers. \n",
    "\n",
    "Similar to the Pearson function above, the `scipy.stats.spearmanr()` function takes two parameters, each a list of values for the two variables being compared. \n",
    "\n",
    "You'll need to create an `unrolled` DataFrame with one row for each injured passenger. Each row should have two values: one for the age band of the driver, and one for the age band of a passenger. If the vehicle has multiple passengers, the DataFrame should have one row for each passenger. (Each element of `Casualties` has a `Vehicle_Reference` that relates it to the vehicle the casualty was in.)\n",
    "\n",
    "We're interested in the relationship between drivers and passengers, so don't include the driver as a casualty. (Use the `Casualty_Class` to find out.)\n",
    "\n",
    "Don't include any driver-passenger pairs where the age of one of them is unknown (code -1).\n",
    "\n",
    "**Hint**\n",
    "\n",
    "Each accident document contains a list of vehicles and a list of casualties. For each accident, you'll need to iterate through both of these to find the information for each individual casualty.\n",
    "\n",
    "The solution is in the [`14.3solutions`](14.3solutions.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared example 1: hypothetical voting intention\n",
    "This is the same example as used in the teaching material, showing how the chi-squared statistic is calculated.\n",
    "\n",
    "Note this way of creating a DataFrame. It's a `dict`, where each entry is a column in the DataFrame. The key is the column name, the value is the items in the column. Each set of column values is itself a `dict`, with one key for each index entry and the value being the contents of that cell in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_survey_results = pd.DataFrame({'Conservative': {'Men': 170, 'Women': 220},\n",
    "                      'Labour': {'Men': 240, 'Women': 190},\n",
    "                      'Other': {'Men': 80, 'Women': 100}})\n",
    "actual_survey_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could find the expected counts manually, or we could use the `scipy.stats.contingency.expected_freq()` function to do it for us. Note that this returns an array, rather than a DataFrame, but it's the same shape as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.contingency.expected_freq(actual_survey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expected_of_df(actual_df):\n",
    "    df = pd.DataFrame(\n",
    "        {c: \n",
    "         {r: actual_df[c].sum() * actual_df.loc[r].sum() / actual_df.sum().sum()\n",
    "                  for r in actual_df[c].index} \n",
    "              for c in actual_df})\n",
    "    # Fix the order of columns and rows\n",
    "    df = df[actual_df.columns]\n",
    "    df = df.reindex(actual_df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_survey_results = expected_of_df(actual_survey_results)\n",
    "expected_survey_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're using a table of several rows and columns, we use the `scipy.stats.chi2_contingency()` function to find the $\\chi ^ 2$ statistic and the _p_ value. \n",
    "\n",
    "Note that the function returns $\\chi ^ 2$, the _p_ value, the number of degrees of freedom, and the matrix of expected frequencies. We're generally after just the second returned value, the _p_ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.chi2_contingency(actual_survey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chi2, p, _, _ = scipy.stats.chi2_contingency(actual_survey_results)\n",
    "chi2, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *p* value of 0.0009 means that we can reject the null hypothesis that voting intention is independent of gender: for this example, it seems that we can say that men and women vote differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we adjust the numbers slightly, we can get a very different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_survey_results_2 = pd.DataFrame({'Conservative': {'Men': 170, 'Women': 220},\n",
    "                      'Labour': {'Men': 220, 'Women': 210},\n",
    "                      'Other': {'Men': 80, 'Women': 100}})\n",
    "actual_survey_results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_survey_results_2 = expected_of_df(actual_survey_results_2)\n",
    "expected_survey_results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chi2, p, _, _ = scipy.stats.chi2_contingency(actual_survey_results_2)\n",
    "chi2, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *p* value of 0.07 means that we *cannot* reject the null hypothesis that voting intention is independent of gender: for this modified example, we can't say that men and women vote differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi square example 2: accident frequency by day of week\n",
    "Let's look to see if more accidents occur on different days of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a DataFrame, one row for each accident\n",
    "count_by_day_unrolled_df = pd.DataFrame(list(accidents.find({}, ['Day_of_Week'])))\n",
    "\n",
    "# Find counts for each day\n",
    "count_by_day_ss = count_by_day_unrolled_df['Day_of_Week'].value_counts()\n",
    "\n",
    "# Reorder by day of week, add labels.\n",
    "count_by_day_ss.sort_index(inplace=True)\n",
    "count_by_day_ss.index = [label_of['Day_of_Week', r] for r in count_by_day_ss.index]\n",
    "\n",
    "count_by_day_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_by_day_ss.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are differences, but are they significant?\n",
    "\n",
    "We run into a slight problem here, though: the functions we used in the voting example above assume the data is in a table of at least two rows and columns. They don't work on one-dimensional series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.contingency.expected_freq(count_by_day_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.chi2_contingency(count_by_day_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we have to use less convenient functions to calculate the $\\chi^2$ and _p_ values. First, we explicitly find the expected values, then we use the `scipy.stats.chisquare()` function to find the test results. Note that the _p_ value is nicely labelled for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_count_by_day_ss = pd.Series(count_by_day_ss.sum() / len(count_by_day_ss), \n",
    "                                  index=count_by_day_ss.index)\n",
    "expected_count_by_day_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.chisquare(count_by_day_ss, expected_count_by_day_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *p* value of zero shows that this is a significant result, and that the varying number of accidents by day is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activityAns"
   },
   "source": [
    "### Activity 2\n",
    "We might expect there to be more accidents in bad weather. We might also expect that weather conditions will affect different roads differently, with bad conditions on high-speed roads having more of an impact on accident likelihood than low-speed (typically urban) roads.\n",
    "\n",
    "If the weather affects all roads equally, we would expect to see the proportions of accidents in different weathers to be the same for different road speed limits. \n",
    "\n",
    "Use a chi-squared test to determine if the proportion of accidents in different weather conditions is independent of road speed.\n",
    "\n",
    "Note that this activity will require several stages, following the pattern above: finding the values for the different ranges of `Weather_Conditions`, extracting the data from the database into a DataFrame, calculating the expected values for each combination of speed limit and weather, and finally calculating the chi-squared *p* value.\n",
    "\n",
    "The solution is in the [`14.3solutions`](14.3solutions.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "If you are working through this Notebook as part of an inline exercise, return to the module materials now.\n",
    "\n",
    "If you are working through this set of Notebooks as a whole, move on to `14.4 Regression on subgroups`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
